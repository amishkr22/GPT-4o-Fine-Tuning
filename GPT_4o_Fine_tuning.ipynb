{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrHrcPmzYETn",
        "outputId": "1e58c5c3-8308-4648-b9a0-9214ab6cabc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting openai\n",
            "  Downloading openai-1.42.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.42.0-py3-none-any.whl (362 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.9/362.9 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, pyarrow, jiter, h11, dill, multiprocess, httpcore, httpx, openai, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.21.0 dill-0.3.8 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jiter-0.5.0 multiprocess-0.70.16 openai-1.42.0 pyarrow-17.0.0 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Pre Processing Dataset**"
      ],
      "metadata": {
        "id": "xrKam8aBFCB7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vP0cKvWmX8I9"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3l4GKbDBYSto"
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\"garage-bAInd/Open-Platypus\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13HegAfvZ0F3",
        "outputId": "ec6a325f-3de1-4dc9-a766-b974b50e3a8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input', 'output', 'instruction', 'data_source'],\n",
              "        num_rows: 24926\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = dataset['train']"
      ],
      "metadata": {
        "id": "d0i5CB6vwWin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9S0Kefuw0CP",
        "outputId": "9b9d2487-8516-48b7-b90f-6d094365148a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input', 'output', 'instruction', 'data_source'],\n",
              "    num_rows: 24926\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wln1GTExb-bV"
      },
      "outputs": [],
      "source": [
        "system_message = {\"role\": \"system\", \"content\": \"Marv is a factual chatbot that is also sarcastic.\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPzsHFXUZ690"
      },
      "outputs": [],
      "source": [
        "def convert_to_conversation(row):\n",
        "    conversation = {\n",
        "        \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": system_message[\"content\"]},\n",
        "            {\"role\": \"user\", \"content\": row['instruction']},\n",
        "            {\"role\": \"assistant\", \"content\": row['output']}\n",
        "        ]\n",
        "    }\n",
        "    return conversation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REeLljVCbmV4"
      },
      "outputs": [],
      "source": [
        "conversations = train_dataset.map(convert_to_conversation, remove_columns=train_dataset.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9n8R9Ui3c3Dp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6515c91a-8b72-465b-c042-ee8958cb944b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'messages': [{'content': 'Marv is a factual chatbot that is also sarcastic.', 'role': 'system'}, {'content': 'A board game spinner is divided into three parts labeled $A$, $B$  and $C$. The probability of the spinner landing on $A$ is $\\\\frac{1}{3}$ and the probability of the spinner landing on $B$ is $\\\\frac{5}{12}$.  What is the probability of the spinner landing on $C$? Express your answer as a common fraction.', 'role': 'user'}, {'content': 'To find the probability of the spinner landing on $C$, I need to subtract the probabilities of the spinner landing on $A$ and $B$ from $1$, since the sum of the probabilities of all possible outcomes is $1$. I can write this as an equation: $P(C) = 1 - P(A) - P(B)$. I know that $P(A) = \\\\frac{1}{3}$ and $P(B) = \\\\frac{5}{12}$, so I can plug those values into the equation and simplify. I get: $P(C) = 1 - \\\\frac{1}{3} - \\\\frac{5}{12} = \\\\frac{12}{12} - \\\\frac{4}{12} - \\\\frac{5}{12} = \\\\frac{3}{12}$. I can reduce this fraction by dividing the numerator and denominator by $3$, and I get: $P(C) = \\\\frac{1}{4}$. ', 'role': 'assistant'}]}\n",
            "{'messages': [{'content': 'Marv is a factual chatbot that is also sarcastic.', 'role': 'system'}, {'content': \"My school's math club has 6 boys and 8 girls.  I need to select a team to send to the state math competition.  We want 6 people on the team.  In how many ways can I select the team without restrictions?\", 'role': 'user'}, {'content': 'I need to choose 6 people out of 14, and the order does not matter. This is a combination problem, not a permutation problem. The formula for combinations is nCr = n! / (r! * (n-r)!), where n is the total number of choices and r is the number of selections. Plugging in the numbers, I get 14C6 = 14! / (6! * 8!) = 3003. ', 'role': 'assistant'}]}\n",
            "{'messages': [{'content': 'Marv is a factual chatbot that is also sarcastic.', 'role': 'system'}, {'content': 'How many 4-letter words with at least one consonant can be constructed from the letters $A$, $B$, $C$, $D$, and $E$?  (Note that $B$, $C$, and $D$ are consonants, any word is valid, not just English language words, and letters may be used more than once.)', 'role': 'user'}, {'content': 'First we count the number of all 4-letter words with no restrictions on the word. Then we count the number of 4-letter words with no consonants. We then subtract to get the answer.\\n\\nEach letter of a word must be one of $A$, $B$, $C$, $D$, or $E$, so the number of 4-letter words with no restrictions on the word is $5\\\\times 5\\\\times 5\\\\times 5=625$.  Each letter of a word with no consonant must be one of $A$ or $E$. So the number of all 4-letter words with no consonants is $2\\\\times 2\\\\times 2\\\\times 2=16$.  Therefore, the number of 4-letter words with at least one consonant is $625-16=609$.', 'role': 'assistant'}]}\n"
          ]
        }
      ],
      "source": [
        "for i in range(3):\n",
        "    print(conversations[i])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye5RnNmJb70P",
        "outputId": "76c0f85b-9ce0-4366-ada8-bd8a59c5df57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['messages'],\n",
              "    num_rows: 24926\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Selected randomly 1000 rows for cost efficiency\n",
        "shuffled_conversations = conversations.shuffle(seed=42)\n",
        "sampled_conversations = shuffled_conversations.select(range(1000))"
      ],
      "metadata": {
        "id": "621R4kUJbbh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(3):\n",
        "    print(sampled_conversations[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC13vF_rbmMP",
        "outputId": "59343930-6ccb-4e58-db81-d0c171bb51d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'messages': [{'content': 'Marv is a factual chatbot that is also sarcastic.', 'role': 'system'}, {'content': 'Given a list of 24-hour clock time points in **\"HH:MM \"** format, return _the minimum **minutes** difference between any two time-points in the list_.\\n\\n**Example 1:**\\n\\n**Input:** timePoints = \\\\[\"23:59\",\"00:00\"\\\\]\\n**Output:** 1\\n\\n**Example 2:**\\n\\n**Input:** timePoints = \\\\[\"00:00\",\"23:59\",\"00:00\"\\\\]\\n**Output:** 0\\n\\n**Constraints:**\\n\\n*   `2 <= timePoints.length <= 2 * 104`\\n*   `timePoints[i]` is in the format **\"HH:MM \"**.\\n', 'role': 'user'}, {'content': \"\\ndef findMinDifference(timePoints):\\n    timePoints.sort()\\n    min_difference = float('inf')\\n\\n    for i in range(len(timePoints)):\\n        h1, m1 = map(int, timePoints[i].split(':'))\\n        h2, m2 = map(int, timePoints[(i+1) % len(timePoints)].split(':'))\\n        cur_difference = abs((h1 * 60 + m1) - (h2 * 60 + m2))\\n        min_difference = min(min_difference, 1440 - cur_difference if cur_difference > 720 else cur_difference)\\n\\n    return min_difference\\n\", 'role': 'assistant'}]}\n",
            "{'messages': [{'content': 'Marv is a factual chatbot that is also sarcastic.', 'role': 'system'}, {'content': 'If $\\\\det \\\\mathbf{A} = 4$ and $\\\\det \\\\mathbf{B} = -5,$ then find $\\\\det (\\\\mathbf{A} \\\\mathbf{B}).$', 'role': 'user'}, {'content': 'I know that the determinant of a product of two matrices is equal to the product of their determinants, as long as they are both square matrices of the same size. So, $\\\\det (\\\\mathbf{A} \\\\mathbf{B}) = \\\\det \\\\mathbf{A} \\\\det \\\\mathbf{B} = 4 \\\\cdot (-5) = -20.$ ', 'role': 'assistant'}]}\n",
            "{'messages': [{'content': 'Marv is a factual chatbot that is also sarcastic.', 'role': 'system'}, {'content': 'Does this passage describe the weather or the climate?\\nSeattle, Washington, has over 200 cloudy days every year.\\nA: weather\\nB: climate', 'role': 'user'}, {'content': 'Read the text carefully.\\nSeattle, Washington, has over 200 cloudy days every year.\\nThis passage tells you about the usual pattern of clouds in Seattle. It does not describe what the weather is like on a particular day. So, this passage describes the climate.', 'role': 'assistant'}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_conversations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAFmagefbtHX",
        "outputId": "11a935a3-057f-4575-c586-18c52bf7deb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['messages'],\n",
              "    num_rows: 1000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Validating - Preprocessed Dataset**"
      ],
      "metadata": {
        "id": "ThhDu7HWDzPi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "def validate_dataset(dataset):\n",
        "    format_errors = defaultdict(int)\n",
        "\n",
        "    for ex in dataset:\n",
        "        if not isinstance(ex, dict):\n",
        "            format_errors[\"data_type\"] += 1\n",
        "            continue\n",
        "\n",
        "        messages = ex.get(\"messages\", None)\n",
        "        if not messages:\n",
        "            format_errors[\"missing_messages_list\"] += 1\n",
        "            continue\n",
        "\n",
        "        for message in messages:\n",
        "            if \"role\" not in message or \"content\" not in message:\n",
        "                format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "            if any(k not in (\"role\", \"content\", \"name\", \"function_call\", \"weight\") for k in message):\n",
        "                format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "            if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
        "                format_errors[\"unrecognized_role\"] += 1\n",
        "\n",
        "            content = message.get(\"content\", None)\n",
        "            function_call = message.get(\"function_call\", None)\n",
        "\n",
        "            if (not content and not function_call) or not isinstance(content, str):\n",
        "                format_errors[\"missing_content\"] += 1\n",
        "\n",
        "        if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "            format_errors[\"example_missing_assistant_message\"] += 1\n",
        "\n",
        "    return format_errors\n",
        "\n",
        "validation_errors = validate_dataset(sampled_conversations)\n",
        "\n",
        "if validation_errors:\n",
        "    print(\"Found errors:\")\n",
        "    for k, v in validation_errors.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "else:\n",
        "    print(\"No errors found\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxGIw5K8wrTk",
        "outputId": "af6886f9-c378-4c3a-db62-821e1771986e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Uploading File to OpenAI Database**"
      ],
      "metadata": {
        "id": "oAhEw-_WD-Y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# File path for JSONL output\n",
        "jsonl_file_path = \"converted_train_dataset.jsonl\"\n",
        "\n",
        "# Function to write dataset to JSONL\n",
        "def save_as_jsonl(dataset, file_path):\n",
        "    with open(file_path, 'w') as file:\n",
        "        for example in dataset:\n",
        "            json_line = json.dumps(example)\n",
        "            file.write(json_line + '\\n')\n",
        "\n",
        "# Convert and save the dataset\n",
        "save_as_jsonl(sampled_conversations, jsonl_file_path)\n",
        "\n",
        "print(f\"Dataset has been saved to {jsonl_file_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FJ1qllRzhRC",
        "outputId": "c3d7591e-a122-4816-bf45-03ff76b1abbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset has been saved to converted_train_dataset.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Fine Tuning**"
      ],
      "metadata": {
        "id": "fXlaeEW6EnZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "client = OpenAI(api_key=OPENAI_KEY)"
      ],
      "metadata": {
        "id": "6axof74OI3Mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client.files.create(\n",
        "  file=open(\"converted_train_dataset.jsonl\", \"rb\"),\n",
        "  purpose=\"fine-tune\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_XeVyVw0drs",
        "outputId": "cd909870-63be-46fd-fdfe-a41128f3f378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FileObject(id='file-Mvv9ZpelR9EHnCV2jUlLLepo', bytes=1358784, created_at=1724340438, filename='converted_train_dataset.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.create(\n",
        "  training_file=\"your_file_id\",\n",
        "  model=\"gpt-4o-2024-08-06\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMdYHKOH09ru",
        "outputId": "d46b3e05-87fa-48a5-a88f-76f19302bf6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-26sPS8L0l6PKz4BpllNPAyix', created_at=1724340459, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-AprgvJhrjCa6ZNkSKpE8gSDt', result_files=[], seed=1768581849, status='validating_files', trained_tokens=None, training_file='file-Mvv9ZpelR9EHnCV2jUlLLepo', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "client.fine_tuning.jobs.retrieve(\"your_job_id\") # To know the status"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nq7pC7ZI1dN2",
        "outputId": "12507bee-d426-47fd-bbd8-dd91d6551e30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "FineTuningJob(id='ftjob-26sPS8L0l6PKz4BpllNPAyix', created_at=1724340459, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs=3, batch_size=2, learning_rate_multiplier=1.8), model='gpt-4o-mini-2024-07-18', object='fine_tuning.job', organization_id='org-AprgvJhrjCa6ZNkSKpE8gSDt', result_files=[], seed=1768581849, status='validating_files', trained_tokens=None, training_file='file-Mvv9ZpelR9EHnCV2jUlLLepo', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message = [\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Hello!\"}\n",
        "  ]\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"gpt-4o-2024-08-06\",\n",
        "  messages=message\n",
        ")\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "id": "yt8kbwj42eTU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "977abe46-e184-44dd-bdf8-f81feb7dbb8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='Hi there! How can I assist you today?', refusal=None, role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"A fair coin is flipped 7 times. What is the probability that at least 5 of the flips come up heads?\""
      ],
      "metadata": {
        "id": "I3oizxaMdAjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "message.append({\"role\": \"user\", \"content\": query})\n",
        "completion = client.chat.completions.create(\n",
        "  model=\"fine-tuning-id\",\n",
        "  messages=message\n",
        ")\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyMWHOwCde31",
        "outputId": "7e9f8490-8265-44f9-a13b-a836c4a3287c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To find the probability that at least 5 out of 7 flips of a fair coin are heads, we can calculate the probabilities of getting exactly 5 heads, exactly 6 heads, and exactly 7 heads, then add them together. \n",
            "\n",
            "Let H represent heads and T represent tails. The total number of outcomes for 7 flips is \\(2^7 = 128\\).\n",
            "\n",
            "1. **Exactly 5 heads (and 2 tails):**\n",
            "   There are \\(\\binom{7}{5} = 21\\) ways to choose which 5 out of 7 flips are heads. Each of these outcomes has a probability of \\(\\left(\\frac{1}{2}\\right)^7 = \\frac{1}{128}\\). So the probability of getting exactly 5 heads is:\n",
            "   \\[P(\\text{exactly 5 heads}) = 21 \\cdot \\frac{1}{128} = \\frac{21}{128}\\]\n",
            "\n",
            "2. **Exactly 6 heads (and 1 tail):**\n",
            "   There are \\(\\binom{7}{6} = 7\\) ways to choose which 6 out of 7 flips are heads. Each of these outcomes has a probability of \\(\\left(\\frac{1}{2}\\right)^7 = \\frac{1}{128}\\). So the probability of getting exactly 6 heads is:\n",
            "   \\[P(\\text{exactly 6 heads}) = 7 \\cdot \\frac{1}{128} = \\frac{7}{128}\\]\n",
            "\n",
            "3. **Exactly 7 heads:**\n",
            "   There is \\(\\binom{7}{7} = 1\\) way to have all 7 flips be heads, which has a probability of \\(\\left(\\frac{1}{2}\\right)^7 = \\frac{1}{128}\\). So the probability of getting exactly 7 heads is:\n",
            "   \\[P(\\text{exactly 7 heads}) = 1 \\cdot \\frac{1}{128} = \\frac{1}{128}\\]\n",
            "\n",
            "Finally, we add these probabilities together to find the probability of having at least 5 heads:\n",
            "\\[\n",
            "P(\\text{at least 5 heads}) = P(\\text{exactly 5 heads}) + P(\\text{exactly 6 heads}) + P(\\text{exactly 7 heads}) = \\frac{21}{128} + \\frac{7}{128} + \\frac{1}{128} = \\frac{29}{128}\n",
            "\\]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}